{"cells":[{"cell_type":"markdown","metadata":{"id":"nb_xI1l-A5R6"},"source":["<h1>Pipeline Final</h1>"]},{"cell_type":"markdown","metadata":{"id":"LWqvxs1QA5SK"},"source":["## Chargement des packages"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:29:58.209459Z","start_time":"2020-10-30T01:29:56.398724Z"},"id":"vhQx_RgzA5SL","outputId":"0b51e78d-8657-41fa-c9d6-2426f8e71285","executionInfo":{"status":"ok","timestamp":1751455047516,"user_tz":-120,"elapsed":18,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"colab":{"base_uri":"https://localhost:8080/","height":17}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>.container { width:100% !important; }</style>"]},"metadata":{}}],"source":["# importation de structures de données utiles\n","import pandas as pd\n","import numpy as np\n","\n","# importation de bibliothèques diverses\n","import os\n","import gc\n","import pickle\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')\n","from datetime import datetime\n","\n","# pour une largeur de cellule à 100 % dans Jupyter Notebook\n","from IPython.core.display import display, HTML\n","display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n","\n","# sklearn\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.ensemble import RandomForestClassifier\n","\n","import xgboost as xgb\n","from xgboost import XGBClassifier\n","from xgboost import XGBRegressor"]},{"cell_type":"code","source":["!pip install xgboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPWw5xJ4Yb-1","executionInfo":{"status":"ok","timestamp":1751455065837,"user_tz":-120,"elapsed":15734,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"outputId":"004d2a9b-d8e9-463c-d1fc-c1b0a773a558"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n"]}]},{"cell_type":"code","source":["!pip install lightgbm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSBwAiY9Yhoc","executionInfo":{"status":"ok","timestamp":1751455078133,"user_tz":-120,"elapsed":12299,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"outputId":"c2585b17-3779-4642-f880-99b19d136db3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1Y985b73kof","executionInfo":{"status":"ok","timestamp":1751455102466,"user_tz":-120,"elapsed":19730,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"outputId":"1031e7d9-caca-45cf-c935-ec7b10f1d949"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# !ls /content/drive/MyDrive/Scoring-Projet/data"],"metadata":{"id":"XW1BKoWU3ssA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3FPqTKLVA5SN"},"source":["## Pipeline"]},{"cell_type":"code","source":["\n","# --- 1. Définition des fonctions de prétraitement et d'ingénierie des caractéristiques ---\n","# Encapsulation des fonctions de prétraitement et de chargement des fichiers\n","\n","class PreprocessingHandler:\n","    def __init__(self, file_directory=''):\n","        self.file_directory = file_directory\n","        self.relational_table = None\n","        # Changé en final_cols_for pour le distinguer de columns_for_modelling\n","        self.final_cols = None\n","        self.columns_for_modelling = None\n","        self.xgbr_ext_1 = None\n","        self.xgbr_ext_2 = None\n","        self.xgbr_ext_3 = None\n","        self.cnt_payment_lgbmr = None\n","        self.TARGET = None\n","        self.knn_target_500_neighbors = None\n","        self.group_interactions_tables = []\n","        self.load_required_files()\n","\n","    def load_required_files(self):\n","        '''\n","        Fonction pour charger tous les fichiers nécessaires au prétraitement et à la prédiction.\n","        Elle est appelée lors de l'initialisation de la classe.\n","\n","        Entrées :\n","            self\n","\n","        Sorties :\n","            Aucune\n","        '''\n","        print(\"Chargement des fichiers requis pour le prétraitement...\")\n","        try:\n","            # Chargement des fichiers importants\n","            with open(self.file_directory + 'relational_table1.pkl', 'rb') as f:\n","                self.relational_table = pickle.load(f)\n","            # Chargement de la liste finale des colonnes pour l’alignement\n","            # Changé en final_cols_for_align\n","            with open(self.file_directory + 'columns_to_select.pkl', 'rb') as f:\n","                self.final_cols = pickle.load(f)\n","            # Chargement des colonnes utilisées pour la modélisation des EXT_SOURCE\n","            with open(self.file_directory + 'columns_for_ext_values_predictor.pkl', 'rb') as f:\n","                self.columns_for_modelling = pickle.load(f)\n","            # Chargement des modèles XGBRegressor pour prédire les champs EXT_SOURCE manquants\n","            with open(self.file_directory + 'nan_EXT_SOURCE_1_xgbr_model.pkl', 'rb') as f:\n","                self.xgbr_ext_1 = pickle.load(f)\n","            # Nom de fichier corrigé pour inclure l'extension .pkl\n","            with open(self.file_directory + 'nan_EXT_SOURCE_2_xgbr_model.pkl', 'rb') as f:\n","                self.xgbr_ext_2 = pickle.load(f)\n","            with open(self.file_directory + 'nan_EXT_SOURCE_3_xgbr_model.pkl', 'rb') as f:\n","                self.xgbr_ext_3 = pickle.load(f)\n","            # Chargement du modèle LGBMRegressor pour prédire le nombre de paiements\n","            with open(self.file_directory + 'cnt_payment_predictor_lgbmr.pkl', 'rb') as f:\n","                self.cnt_payment_lgbmr = pickle.load(f)\n","            # Chargement des valeurs cibles d'entraînement\n","            with open(self.file_directory + 'Train_TARGET.pkl', 'rb') as f:\n","                self.TARGET = pickle.load(f)\n","            # Chargement du modèle KNN pour la caractéristique TARGET_500_neighbors\n","            with open(self.file_directory + 'KNN_model_TARGET_500_neighbors.pkl', 'rb') as f:\n","                self.knn_target_500_neighbors = pickle.load(f)\n","            # Chargement des interactions groupées pour plusieurs regroupements\n","            file_names = ['Application_train_grouped_interactions_NAME_CONTRACT_TYPE_NAME_INCOME_TYPE_OCCUPATION_TYPE.pkl',\n","                          'Application_train_grouped_interactions_CODE_GENDER_NAME_FAMILY_STATUS_NAME_INCOME_TYPE.pkl',\n","                          'Application_train_grouped_interactions_FLAG_OWN_CAR_FLAG_OWN_REALTY_NAME_INCOME_TYPE.pkl',\n","                          'Application_train_grouped_interactions_NAME_EDUCATION_TYPE_NAME_INCOME_TYPE_OCCUPATION_TYPE.pkl',\n","                          'Application_train_grouped_interactions_OCCUPATION_TYPE_ORGANIZATION_TYPE.pkl',\n","                          'Application_train_grouped_interactions_CODE_GENDER_FLAG_OWN_CAR_FLAG_OWN_REALTY.pkl']\n","            for group_interactions_file_name in file_names:\n","                group_file_path = self.file_directory + 'Grouped Interactions/' + group_interactions_file_name\n","                if os.path.exists(group_file_path):\n","                    with open(group_file_path, 'rb') as f:\n","                        self.group_interactions_tables.append(pickle.load(f))\n","                else:\n","                    print(f\"Attention : fichier d'interactions groupées introuvable à {group_file_path}. Ignoré.\")\n","\n","            print(\"Tous les fichiers requis ont été chargés avec succès.\")\n","        except FileNotFoundError as e:\n","            print(f\"Erreur de chargement du fichier : {e}. Veuillez vérifier que tous les fichiers .pkl nécessaires sont présents dans le répertoire spécifié et ses sous-dossiers.\")\n","            raise\n","        except Exception as e:\n","            print(f\"Une erreur inattendue est survenue lors du chargement des fichiers : {e}\")\n","            raise\n","\n","    def create_new_features(self, data):\n","        '''\n","        Fonction pour créer de nouvelles variables après la fusion des caractéristiques,\n","        en utilisant les interactions entre différentes tables.\n","\n","        Entrées :\n","            data : DataFrame\n","\n","        Sorties :\n","            DataFrame avec de nouvelles variables\n","        '''\n","        print(\"Creating new features...\")\n","        # Liste des colonnes de \"flag\" à supprimer car elles sont considérées comme non utiles\n","        flag_cols_to_drop = ['FLAG_DOCUMENT_2','FLAG_DOCUMENT_4','FLAG_DOCUMENT_10','FLAG_DOCUMENT_12',\n","                             'FLAG_DOCUMENT_20']\n","        data = data.drop(flag_cols_to_drop, axis = 1, errors='ignore') # Suppression des colonnes spécifiées\n","        # Conversion de l'âge en années (DAYS_BIRTH est généralement en jours négatifs)\n","        data['DAYS_BIRTH'] = data['DAYS_BIRTH'] * -1 / 365\n","        # Suppression des points erronés ou des valeurs aberrantes\n","        # Les valeurs 365243 dans DAYS_EMPLOYED sont remplacées par NaN (valeur manquante)\n","        data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].replace({365243: np.nan})\n","        # Les valeurs aberrantes (> 30) dans les colonnes de cercle social sont remplacées par NaN\n","        data['OBS_30_CNT_SOCIAL_CIRCLE'] = data['OBS_30_CNT_SOCIAL_CIRCLE'].replace(to_replace=r'^3[1-9]+|[4-9][0-9]*$', value=np.nan, regex=True)\n","        data['OBS_60_CNT_SOCIAL_CIRCLE'] = data['OBS_60_CNT_SOCIAL_CIRCLE'].replace(to_replace=r'^3[1-9]+|[4-9][0-9]*$', value=np.nan, regex=True)\n","\n","        # Remplissage des valeurs NaN pour les colonnes catégorielles avec 'XNA'\n","        categorical_columns = data.dtypes[data.dtypes == 'object'].index.tolist() # Obtient la liste des colonnes de type 'object' (catégorielles)\n","        data[categorical_columns] = data[categorical_columns].fillna('XNA') # Remplit les NaN avec 'XNA'\n","        # Conversion des colonnes de notation de région en type 'object' (catégoriel)\n","        data['REGION_RATING_CLIENT'] = data['REGION_RATING_CLIENT'].astype('object')\n","        data['REGION_RATING_CLIENT_W_CITY'] = data['REGION_RATING_CLIENT_W_CITY'].astype('object')\n","        # Comptage du nombre total de valeurs manquantes pour chaque demande (ligne)\n","        data['MISSING_VALS_TOTAL_APP'] = data.isna().sum(axis = 1) # Calcule la somme des NaN par ligne\n","\n","        # Nous devons prédire les valeurs manquantes de EXT_SOURCE s'il y en a\n","        columns_for_modelling_ext = list(self.columns_for_modelling)\n","        xgbr_ext_models = [self.xgbr_ext_2, self.xgbr_ext_3, self.xgbr_ext_1]\n","        # Itération sur les colonnes EXT_SOURCE pour prédire les valeurs manquantes\n","        for index, ext_col in enumerate(['EXT_SOURCE_2','EXT_SOURCE_3','EXT_SOURCE_1']):\n","            # Vérifie si des valeurs sont manquantes dans la colonne EXT_SOURCE actuelle\n","            if ext_col in data.columns and data[ext_col].isna().sum() > 0:\n","                # Sélectionne les lignes avec des valeurs manquantes et les colonnes pertinentes pour la prédiction\n","                cols_present_in_data = [col for col in columns_for_modelling_ext if col in data.columns]\n","                X_test_missing = data.loc[data[ext_col].isna(), cols_present_in_data]\n","                try:\n","                    predicted_values = xgbr_ext_models[index].predict(X_test_missing)\n","                    data.loc[data[ext_col].isna(), ext_col] = predicted_values\n","                except Exception as e:\n","                     print(f\"Error predicting missing values for {ext_col}: {e}\")\n","                     data.loc[data[ext_col].isna(), ext_col] = data[ext_col].median() if not data[ext_col].median() == np.nan else 0.0 # Or 0.0 or mean()\n","\n","            # Ajoute la colonne prédite aux colonnes utilisées pour la modélisation pour la prédiction des colonnes suivantes\n","            if ext_col not in columns_for_modelling_ext:\n","                 columns_for_modelling_ext.append(ext_col)\n","\n","        # Création de nouvelles caractéristiques numériques\n","\n","        # Caractéristiques de revenu et de crédit\n","        data['CREDIT_INCOME_RATIO'] = data['AMT_CREDIT'] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Ratio crédit / revenu\n","        data['CREDIT_ANNUITY_RATIO'] = data['AMT_CREDIT'] / (data['AMT_ANNUITY'] + 0.00001) # Ratio crédit / annuité\n","        data['ANNUITY_INCOME_RATIO'] = data['AMT_ANNUITY'] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Ratio annuité / revenu\n","        data['INCOME_ANNUITY_DIFF'] = data['AMT_INCOME_TOTAL'] - data['AMT_ANNUITY'] # Différence revenu - annuité\n","        data['CREDIT_GOODS_RATIO'] = data['AMT_CREDIT'] / (data['AMT_GOODS_PRICE'] + 0.00001) # Ratio crédit / prix des biens\n","        data['CREDIT_GOODS_DIFF'] = data['AMT_CREDIT'] - data['AMT_GOODS_PRICE'] + 0.00001 # Différence crédit - prix des biens\n","        data['GOODS_INCOME_RATIO'] = data['AMT_GOODS_PRICE'] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Ratio prix des biens / revenu\n","        # Add checks for EXT_SOURCE_3 before division\n","        data['INCOME_EXT_RATIO'] = data['AMT_INCOME_TOTAL'] / (data['EXT_SOURCE_3'].replace(0, np.nan) + 0.00001) # Ratio revenu / EXT_SOURCE_3\n","        data['CREDIT_EXT_RATIO'] = data['AMT_CREDIT'] / (data['EXT_SOURCE_3'].replace(0, np.nan) + 0.00001) # Ratio crédit / EXT_SOURCE_3\n","        # Ratios et différences d'âge\n","        data['AGE_EMPLOYED_DIFF'] = data['DAYS_BIRTH'] - data['DAYS_EMPLOYED'] # Différence âge - jours travaillés\n","        data['EMPLOYED_TO_AGE_RATIO'] = data['DAYS_EMPLOYED'] / (data['DAYS_BIRTH'] + 0.00001) # Ratio jours travaillés / âge\n","        # Ratios liés à la voiture\n","        data['CAR_EMPLOYED_DIFF'] = data['OWN_CAR_AGE'] - data['DAYS_EMPLOYED'] # Différence âge voiture - jours travaillés\n","        data['CAR_EMPLOYED_RATIO'] = data['OWN_CAR_AGE'] / (data['DAYS_EMPLOYED']+0.00001) # Ratio âge voiture / jours travaillés\n","        data['CAR_AGE_DIFF'] = data['DAYS_BIRTH'] - data['OWN_CAR_AGE'] # Différence âge - âge voiture\n","        data['CAR_AGE_RATIO'] = data['OWN_CAR_AGE'] / (data['DAYS_BIRTH'] + 0.00001) # Ratio âge voiture / âge\n","        # Somme des drapeaux de contact\n","        data['FLAG_CONTACTS_SUM'] = data['FLAG_MOBIL'] + data['FLAG_EMP_PHONE'] + data['FLAG_WORK_PHONE'] + data[\n","                                     'FLAG_CONT_MOBILE'] + data['FLAG_PHONE'] + data['FLAG_EMAIL'] # Somme des indicateurs de contact\n","\n","        data['HOUR_PROCESS_CREDIT_MUL'] = data['AMT_CREDIT'] * data['HOUR_APPR_PROCESS_START'] # Produit crédit * heure de début de processus\n","        # Membres de la famille\n","        data['CNT_NON_CHILDREN'] = data['CNT_FAM_MEMBERS'] - data['CNT_CHILDREN'] # Nombre de membres de la famille sans enfants\n","        data['CHILDREN_INCOME_RATIO'] = data['CNT_CHILDREN'] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Ratio enfants / revenu total\n","        data['PER_CAPITA_INCOME'] = data['AMT_INCOME_TOTAL'] / (data['CNT_FAM_MEMBERS'] + 1) # Revenu par membre de la famille\n","        # Notations de région\n","        # Ensure columns are numeric before calculation\n","        data['REGIONS_RATING_INCOME_MUL'] = (data['REGION_RATING_CLIENT'].astype(float) + data['REGION_RATING_CLIENT_W_CITY'].astype(float)) * data['AMT_INCOME_TOTAL'] / 2 # Produit moyen des notations de région par le revenu\n","        data['REGION_RATING_MAX'] = [max(float(ele1), float(ele2)) for ele1, ele2 in zip(data['REGION_RATING_CLIENT'], data['REGION_RATING_CLIENT_W_CITY'])] # Maximum des notations de région\n","        # The next line was a copy-paste error in original code, it should be MIN not MAX again. Corrected to MIN\n","        data['REGION_RATING_MIN'] = [min(float(ele1), float(ele2)) for ele1, ele2 in zip(data['REGION_RATING_CLIENT'], data['REGION_RATING_CLIENT_W_CITY'])] # Minimum des notations de région\n","        data['REGION_RATING_MEAN'] = (data['REGION_RATING_CLIENT'].astype(float) + data['REGION_RATING_CLIENT_W_CITY'].astype(float)) / 2 # Moyenne des notations de région\n","        data['REGION_RATING_MUL'] = data['REGION_RATING_CLIENT'].astype(float) * data['REGION_RATING_CLIENT_W_CITY'].astype(float) # Produit des notations de région\n","        # Drapeaux de région combinés\n","        data['FLAG_REGIONS'] = data['REG_REGION_NOT_LIVE_REGION'] + data['REG_REGION_NOT_WORK_REGION'] + data['LIVE_REGION_NOT_WORK_REGION']+data[\n","                                 'REG_CITY_NOT_LIVE_CITY'] + data['REG_CITY_NOT_WORK_CITY'] + data['LIVE_CITY_NOT_WORK_CITY'] # Somme des drapeaux de non-correspondance des régions\n","        # Sources externes (EXT_SOURCE)\n","        # Add checks for EXT_SOURCE columns before calculation\n","        ext_cols = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n","        for col in ext_cols:\n","            if col not in data.columns:\n","                data[col] = np.nan # Ensure columns exist, fill with NaN if missing\n","        data['EXT_SOURCE_MEAN'] = data[ext_cols].mean(axis=1) # Moyenne des sources externes\n","        data['EXT_SOURCE_MUL'] = data['EXT_SOURCE_1'].fillna(data['EXT_SOURCE_1'].mean()) * data['EXT_SOURCE_2'].fillna(data['EXT_SOURCE_2'].mean()) * data['EXT_SOURCE_3'].fillna(data['EXT_SOURCE_3'].mean()) # Produit des sources externes\n","        data['EXT_SOURCE_MAX'] = data[ext_cols].max(axis=1) # Maximum des sources externes\n","        data['EXT_SOURCE_MIN'] = data[ext_cols].min(axis=1) # Minimum des sources externes\n","        data['EXT_SOURCE_VAR'] = data[ext_cols].var(axis=1) # Variance des sources externes\n","        data['WEIGHTED_EXT_SOURCE'] = data['EXT_SOURCE_1'].fillna(0) * 2 + data['EXT_SOURCE_2'].fillna(0) * 3 + data['EXT_SOURCE_3'].fillna(0) * 4 # Somme pondérée des sources externes\n","        # Scores d'appartement\n","        apartment_avg_cols = ['APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG',\n","                              'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG',\n","                              'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG',\n","                              'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG']\n","        for col in apartment_avg_cols:\n","            if col not in data.columns:\n","                data[col] = 0.0\n","        data['APARTMENTS_SUM_AVG'] = data[apartment_avg_cols].sum(axis=1)\n","\n","        apartment_mode_cols = ['APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE',\n","                               'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE',\n","                               'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE',\n","                               'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'TOTALAREA_MODE']\n","        for col in apartment_mode_cols:\n","            if col not in data.columns:\n","                data[col] = 0.0\n","        data['APARTMENTS_SUM_MODE'] = data[apartment_mode_cols].sum(axis=1)\n","\n","        apartment_medi_cols = ['APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI',\n","                               'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI',\n","                               'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI',\n","                               'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI']\n","        for col in apartment_medi_cols:\n","            if col not in data.columns:\n","                data[col] = 0.0\n","        data['APARTMENTS_SUM_MEDI'] = data[apartment_medi_cols].sum(axis=1)\n","\n","        data['INCOME_APARTMENT_AVG_MUL'] = data['APARTMENTS_SUM_AVG'] * data['AMT_INCOME_TOTAL'] # Produit des scores moyens d'appartement par le revenu\n","        data['INCOME_APARTMENT_MODE_MUL'] = data['APARTMENTS_SUM_MODE'] * data['AMT_INCOME_TOTAL'] # Produit des scores modaux d'appartement par le revenu\n","        data['INCOME_APARTMENT_MEDI_MUL'] = data['APARTMENTS_SUM_MEDI'] * data['AMT_INCOME_TOTAL'] # Produit des scores médians d'appartement par le revenu\n","        # OBS et DEF (observations et défauts)\n","        obs_def_cols = ['OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']\n","        for col in obs_def_cols:\n","             if col not in data.columns:\n","                 data[col] = np.nan\n","\n","        data['OBS_30_60_SUM'] = data['OBS_30_CNT_SOCIAL_CIRCLE'].fillna(0) + data['OBS_60_CNT_SOCIAL_CIRCLE'].fillna(0) # Somme des observations à 30 et 60 jours\n","        data['DEF_30_60_SUM'] = data['DEF_30_CNT_SOCIAL_CIRCLE'].fillna(0) + data['DEF_60_CNT_SOCIAL_CIRCLE'].fillna(0) # Somme des défauts à 30 et 60 jours\n","        data['OBS_DEF_30_MUL'] = data['OBS_30_CNT_SOCIAL_CIRCLE'].fillna(0) * data['DEF_30_CNT_SOCIAL_CIRCLE'].fillna(0) # Produit des observations et défauts à 30 jours\n","        data['OBS_DEF_60_MUL'] = data['OBS_60_CNT_SOCIAL_CIRCLE'].fillna(0) * data['DEF_60_CNT_SOCIAL_CIRCLE'].fillna(0) # Produit des observations et défauts à 60 jours\n","        data['SUM_OBS_DEF_ALL'] = data['OBS_30_CNT_SOCIAL_CIRCLE'].fillna(0) + data['DEF_30_CNT_SOCIAL_CIRCLE'].fillna(0) + data[\n","                                     'OBS_60_CNT_SOCIAL_CIRCLE'].fillna(0) + data['DEF_60_CNT_SOCIAL_CIRCLE'].fillna(0) # Somme de toutes les observations et défauts\n","        data['OBS_30_CREDIT_RATIO'] = data['AMT_CREDIT'] / (data['OBS_30_CNT_SOCIAL_CIRCLE'].replace(0, np.nan).fillna(data['OBS_30_CNT_SOCIAL_CIRCLE'].median()) + 0.00001) # Ratio crédit / observations à 30 jours\n","        data['OBS_60_CREDIT_RATIO'] = data['AMT_CREDIT'] / (data['OBS_60_CNT_SOCIAL_CIRCLE'].replace(0, np.nan).fillna(data['OBS_60_CNT_SOCIAL_CIRCLE'].median()) + 0.00001) # Ratio crédit / observations à 60 jours\n","        data['DEF_30_CREDIT_RATIO'] = data['AMT_CREDIT'] / (data['DEF_30_CNT_SOCIAL_CIRCLE'].replace(0, np.nan).fillna(data['DEF_30_CNT_SOCIAL_CIRCLE'].median()) + 0.00001) # Ratio crédit / défauts à 30 jours\n","        data['DEF_60_CREDIT_RATIO'] = data['AMT_CREDIT'] / (data['DEF_60_CNT_SOCIAL_CIRCLE'].replace(0, np.nan).fillna(data['DEF_60_CNT_SOCIAL_CIRCLE'].median()) + 0.00001) # Ratio crédit / défauts à 60 jours\n","        # Somme des drapeaux de documents combinés\n","        document_flags = ['FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7',\n","                          'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_13',\n","                          'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17',\n","                          'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_21']\n","        for col in document_flags:\n","            if col not in data.columns:\n","                data[col] = 0\n","        data['SUM_FLAGS_DOCUMENTS'] = data[document_flags].sum(axis=1) # Somme de tous les drapeaux de documents (sauf ceux supprimés initialement)\n","        # Changement de détails\n","        data['DAYS_DETAILS_CHANGE_MUL'] = data['DAYS_LAST_PHONE_CHANGE'] * data['DAYS_REGISTRATION'] * data['DAYS_ID_PUBLISH'] # Produit des jours de changement de téléphone, d'enregistrement et de publication d'ID\n","        data['DAYS_DETAILS_CHANGE_SUM'] = data['DAYS_LAST_PHONE_CHANGE'] + data['DAYS_REGISTRATION'] + data['DAYS_ID_PUBLISH'] # Somme des jours de changement de téléphone, d'enregistrement et de publication d'ID\n","        # Enquêtes de crédit\n","        enq_credit_cols = ['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n","                           'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n","        for col in enq_credit_cols:\n","            if col not in data.columns:\n","                data[col] = 0.0\n","        data['AMT_ENQ_SUM'] = data[enq_credit_cols].sum(axis=1) # Somme des demandes de crédit au bureau\n","        data['ENQ_CREDIT_RATIO'] = data['AMT_ENQ_SUM'] / (data['AMT_CREDIT'] + 0.00001) # Ratio demandes de crédit / montant du crédit\n","\n","        # Nous devons prédire le nombre de paiements pour nos données\n","        test_data_for_cnt_payment = data[['AMT_CREDIT','AMT_ANNUITY']].fillna(0) # Crée un DataFrame temporaire avec les colonnes crédit et annuité\n","        test_data_for_cnt_payment['CREDIT_ANNUITY_RATIO'] = test_data_for_cnt_payment['AMT_CREDIT'] / (test_data_for_cnt_payment['AMT_ANNUITY'] + 1) # Calcule le ratio crédit / annuité\n","        cnt_payment = self.cnt_payment_lgbmr.predict(test_data_for_cnt_payment) # Prédit le nombre de paiements en utilisant un modèle LightGBM (stocké dans 'self')\n","        del test_data_for_cnt_payment # Supprime le DataFrame temporaire pour libérer de la mémoire\n","        data['EXPECTED_CNT_PAYMENT'] = cnt_payment # Ajoute le nombre de paiements prédit\n","        data['EXPECTED_INTEREST'] = data['AMT_ANNUITY'] * data['EXPECTED_CNT_PAYMENT'] - data['AMT_CREDIT'] # Calcule l'intérêt attendu\n","        data['EXPECTED_INTEREST_SHARE'] = data['EXPECTED_INTEREST'] / (data['AMT_CREDIT'] + 0.00001) # Calcule la part d'intérêt attendue\n","        data['EXPECTED_INTEREST_RATE'] = 2 * 12 * data['EXPECTED_INTEREST'] / (data['AMT_CREDIT'] * (data['EXPECTED_CNT_PAYMENT'] + 1)) # Calcule le taux d'intérêt attendu\n","\n","        # Prédiction de la moyenne de la variable CIBLE des 500 voisins les plus proches des données de test\n","        ext_knn_cols = ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','CREDIT_ANNUITY_RATIO']\n","        for col in ext_knn_cols:\n","            if col not in data.columns:\n","                data[col] = np.nan\n","        test_data_for_neighbors = data[ext_knn_cols].fillna(0) # Prépare les données pour la recherche des voisins\n","        # Trouve les 500 voisins les plus proches et récupère leurs index\n","        test_500_neighbors = self.knn_target_500_neighbors.kneighbors(test_data_for_neighbors)[1]\n","        # Calcule la moyenne de la variable CIBLE pour ces 500 voisins\n","        data['TARGET_NEIGHBORS_500_MEAN'] = [self.TARGET.iloc[ele].mean() for ele in test_500_neighbors]\n","\n","        # Création de caractéristiques basées sur les interactions catégorielles\n","        columns_to_aggregate_on = [\n","            ['NAME_CONTRACT_TYPE', 'NAME_INCOME_TYPE', 'OCCUPATION_TYPE'],\n","            ['CODE_GENDER', 'NAME_FAMILY_STATUS', 'NAME_INCOME_TYPE'],\n","            ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE'],\n","            ['NAME_EDUCATION_TYPE','NAME_INCOME_TYPE','OCCUPATION_TYPE'],\n","            ['OCCUPATION_TYPE','ORGANIZATION_TYPE'],\n","            ['CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY']\n","        ]\n","        # Pour chaque groupe de colonnes, joindre les statistiques groupées pré-calculées\n","        for index, group in enumerate(columns_to_aggregate_on):\n","            group_stats = self.group_interactions_tables[index]  # Récupérer les statistiques groupées (doivent être pré-calculées et stockées dans 'self')\n","\n","            # Vérifier si toutes les colonnes du groupe existent dans 'data' avant de faire la jointure\n","            if all(col in data.columns for col in group):\n","                # Ajouter un suffixe aux colonnes fusionnées pour éviter les conflits si des noms de colonnes se chevauchent\n","                # En supposant que les colonnes de group_stats sont comme ['group_col1', 'group_col2', 'aggregated_feature']\n","                # Il faut s'assurer que le nom de la colonne de la caractéristique agrégée soit unique\n","                # On suppose ici que cette colonne agrégée est la dernière après les colonnes de regroupement dans group_stats\n","                aggregated_col_name_suffix = '_group_' + '_'.join(group)  # Créer un suffixe unique\n","\n","                # Renommer les colonnes dans group_stats avant la fusion\n","                group_stats_renamed = group_stats.copy()\n","                # En supposant que les colonnes de jointure sont les premières len(group) colonnes\n","                cols_to_rename = group_stats_renamed.columns[len(group):]\n","                rename_dict = {col: col + aggregated_col_name_suffix for col in cols_to_rename}\n","                group_stats_renamed = group_stats_renamed.rename(columns=rename_dict)\n","\n","                data = data.merge(group_stats_renamed, on=group, how='left')  # Joindre les statistiques au DataFrame principal\n","            else:\n","                print(f\"Attention : colonnes manquantes dans les données pour la jointure du groupe : {group}. Fusion ignorée.\")\n","\n","        # Codage de réponse pour les colonnes catégorielles\n","        # Obtient à nouveau la liste des colonnes catégorielles\n","        categorical_columns = data.dtypes[data.dtypes == 'object'].index.tolist()\n","        for col in categorical_columns:\n","            try:\n","                # Charge le dictionnaire de codage de réponse pour la colonne actuelle\n","                mapping_file_path = self.file_directory + 'Response Coding/' + f'Response_coding_dict_{col}.pkl'\n","                if os.path.exists(mapping_file_path):\n","                    with open(mapping_file_path, 'rb') as f:\n","                        mapping_dictionary_column = pickle.load(f)\n","                    data[col + '_0'] = data[col].map(mapping_dictionary_column[0])\n","                    data[col + '_1'] = data[col].map(mapping_dictionary_column[1])\n","                    # Supprimer la variable catégorielle d'origine\n","                    _ = data.pop(col)\n","                else:\n","                    print(f\"Attention : le dictionnaire de codage de réponse pour la colonne '{col}' est introuvable à l'emplacement {mapping_file_path}. Codage de réponse ignoré pour cette colonne.\")\n","            except Exception as e:\n","                print(f\"Erreur lors du codage de réponse pour la colonne '{col}' : {e}. Codage ignoré.\")\n","\n","        # Fusion avec la table relationnelle\n","        if 'SK_ID_CURR' in data.columns and self.relational_table is not None:\n","            if 'SK_ID_CURR' in self.relational_table.columns:\n","                data = data.merge(self.relational_table, on='SK_ID_CURR', how='left')\n","            else:\n","                print(\"Attention : 'SK_ID_CURR' est absent de relational_table. Fusion ignorée.\")\n","        else:\n","            print(\"Attention : 'SK_ID_CURR' est absent de data ou relational_table n'est pas chargée. Fusion ignorée.\")\n","\n","        # Ajout de caractéristiques basées sur les interactions entre différentes tables\n","\n","        # previous_application columns\n","        prev_annuity_columns = ['AMT_ANNUITY_MEAN_LAST_5', 'AMT_ANNUITY_SUM_LAST_5', 'AMT_ANNUITY_MAX_LAST_5', 'AMT_ANNUITY_MEAN_FIRST_2',\n","                                'AMT_ANNUITY_SUM_FIRST_2', 'AMT_ANNUITY_MAX_FIRST_2', 'AMT_ANNUITY_MEAN_ALL', 'AMT_ANNUITY_SUM_ALL', 'AMT_ANNUITY_MAX_ALL']\n","        for col in prev_annuity_columns:\n","            if col in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n","                data['PREV_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Crée des ratios d'annuité par rapport au revenu\n","\n","        prev_goods_columns = ['AMT_GOODS_PRICE_MEAN_LAST_5', 'AMT_GOODS_PRICE_MAX_LAST_5', 'AMT_GOODS_PRICE_SUM_LAST_5', 'AMT_GOODS_PRICE_MEAN_FIRST_2',\n","                              'AMT_GOODS_PRICE_MAX_FIRST_2', 'AMT_GOODS_PRICE_SUM_FIRST_2', 'AMT_GOODS_PRICE_MEAN_ALL', 'AMT_GOODS_PRICE_MAX_ALL',\n","                              'AMT_GOODS_PRICE_SUM_ALL']\n","        for col in prev_goods_columns:\n","            if col in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n","                data['PREV_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Crée des ratios de prix des biens par rapport au revenu\n","\n","        # credit_card_balance columns\n","        cc_amt_principal_cols = ['AMT_RECEIVABLE_PRINCIPAL_SUM', 'AMT_RECEIVABLE_PRINCIPAL_MEAN', 'AMT_RECEIVABLE_PRINCIPAL_MAX', 'EXP_AMT_RECEIVABLE_PRINCIPAL_LAST']\n","        for col in cc_amt_principal_cols:\n","            if col in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n","                data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Crée des ratios de principal à recevoir par rapport au revenu\n","\n","        cc_amt_recivable_cols = ['AMT_RECIVABLE_SUM', 'AMT_RECIVABLE_MEAN', 'AMT_RECIVABLE_MAX', 'EXP_AMT_RECIVABLE_LAST']\n","        for col in cc_amt_recivable_cols:\n","            if col in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n","                data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Crée des ratios d'encours à recevoir par rapport au revenu\n","\n","        cc_amt_total_receivable_cols = ['AMT_TOTAL_RECEIVABLE_SUM', 'AMT_TOTAL_RECEIVABLE_MEAN', 'AMT_TOTAL_RECEIVABLE_MAX', 'EXP_AMT_TOTAL_RECEIVABLE_LAST']\n","        for col in cc_amt_total_receivable_cols:\n","            if col in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n","                data['CC_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Crée des ratios du total à recevoir par rapport au revenu\n","\n","        # installments_payments columns\n","        installments_payment_cols = ['AMT_PAYMENT_MEAN_MEAN', 'AMT_PAYMENT_MEAN_SUM', 'AMT_PAYMENT_MEAN_MAX', 'AMT_PAYMENT_SUM_MEAN', 'AMT_PAYMENT_SUM_SUM',\n","                                     'AMT_PAYMENT_SUM_MAX', 'AMT_PAYMENT_MAX_MEAN', 'AMT_PAYMENT_MEAN_LAST_1_YEAR', 'AMT_PAYMENT_SUM_LAST_1_YEAR',\n","                                     'AMT_PAYMENT_MAX_LAST_1_YEAR', 'AMT_PAYMENT_MEAN_FIRST_5_INSTALLMENTS', 'AMT_PAYMENT_SUM_FIRST_5_INSTALLMENTS',\n","                                     'AMT_PAYMENT_MAX_FIRST_5_INSTALLMENTS']\n","        for col in installments_payment_cols:\n","            if col in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n","                data['INSTALLMENTS_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Crée des ratios de paiement par rapport au revenu\n","\n","        installments_max_installment = ['AMT_INSTALMENT_MEAN_MAX', 'AMT_INSTALMENT_SUM_MAX']\n","        for col in installments_max_installment:\n","            if col in data.columns and 'AMT_ANNUITY' in data.columns:\n","                data['INSTALLMENTS_ANNUITY_' + col + '_RATIO'] = data['AMT_ANNUITY'] / (data[col] + 0.00001) # Crée des ratios d'annuité par rapport aux montants des versements maximaux\n","\n","        # bureau and bureau_balance columns\n","        bureau_days_credit_cols = ['DAYS_CREDIT_MEAN_OVERALL', 'DAYS_CREDIT_MEAN_CREDITACTIVE_CLOSED', 'DAYS_CREDIT_MIN_CREDITACTIVE_CLOSED',\n","                                   'DAYS_CREDIT_MAX_CREDITACTIVE_CLOSED', 'DAYS_CREDIT_LAST_CREDITACTIVE_CLOSED', 'DAYS_CREDIT_MEAN_CREDITACTIVE_ACTIVE',\n","                                   'DAYS_CREDIT_MIN_CREDITACTIVE_ACTIVE', 'DAYS_CREDIT_MAX_CREDITACTIVE_ACTIVE', 'DAYS_CREDIT_LAST_CREDITACTIVE_ACTIVE',\n","                                   'DAYS_CREDIT_MEANCREDIT_ACTIVE_REST', 'DAYS_CREDIT_MINCREDIT_ACTIVE_REST', 'DAYS_CREDIT_MAXCREDIT_ACTIVE_REST',\n","                                   'DAYS_CREDIT_LASTCREDIT_ACTIVE_REST']\n","        for col in bureau_days_credit_cols:\n","            if col in data.columns and 'DAYS_EMPLOYED' in data.columns:\n","                data['BUREAU_' + col + '_EMPLOYED_DIFF'] = data[col] - data['DAYS_EMPLOYED'] # Différence entre jours de crédit et jours travaillés\n","            if col in data.columns and 'DAYS_REGISTRATION' in data.columns:\n","                data['BUREAU_' + col + '_REGISTRATION_DIFF'] = data[col] - data['DAYS_REGISTRATION'] # Différence entre jours de crédit et jours d'enregistrement\n","\n","        bureau_overdue_cols = ['AMT_CREDIT_MAX_OVERDUE_MEAN_OVERALL', 'AMT_CREDIT_SUM_OVERDUE_MEAN_OVERALL', 'AMT_CREDIT_MAX_OVERDUE_MAX_CREDITACTIVE_CLOSED',\n","                               'AMT_CREDIT_MAX_OVERDUE_SUM_CREDITACTIVE_CLOSED', 'AMT_CREDIT_SUM_OVERDUE_MAX_CREDITACTIVE_CLOSED', 'AMT_CREDIT_SUM_OVERDUE_SUM_CREDITACTIVE_CLOSED',\n","                               'AMT_CREDIT_MAX_OVERDUE_MAX_CREDITACTIVE_ACTIVE', 'AMT_CREDIT_MAX_OVERDUE_SUM_CREDITACTIVE_ACTIVE', 'AMT_CREDIT_SUM_OVERDUE_MAX_CREDITACTIVE_ACTIVE',\n","                               'AMT_CREDIT_SUM_OVERDUE_SUM_CREDITACTIVE_ACTIVE', 'AMT_CREDIT_MAX_OVERDUE_MAXCREDIT_ACTIVE_REST', 'AMT_CREDIT_MAX_OVERDUE_SUMCREDIT_ACTIVE_REST',\n","                               'AMT_CREDIT_SUM_OVERDUE_MAXCREDIT_ACTIVE_REST', 'AMT_CREDIT_SUM_OVERDUE_SUMCREDIT_ACTIVE_REST']\n","        for col in bureau_overdue_cols:\n","            if col in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n","                data['BUREAU_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Crée des ratios d'arriérés de crédit par rapport au revenu\n","\n","        bureau_amt_annuity_cols = ['AMT_ANNUITY_MEAN_OVERALL']\n","        for col in bureau_amt_annuity_cols:\n","            if col in data.columns and 'AMT_INCOME_TOTAL' in data.columns:\n","                data['BUREAU_' + col + '_INCOME_RATIO'] = data[col] / (data['AMT_INCOME_TOTAL'] + 0.00001) # Crée des ratios d'annuité du bureau par rapport au revenu\n","\n","\n","        print(\"Création de nouvelles variables.\")\n","        return data\n","\n","# --- 2. Classe principale du pipeline (inspirée de testing_class) ---\n","class FinalPipeline:\n","    def __init__(self, model_path, file_directory=''):\n","        self.model_path = model_path\n","        self.file_directory = file_directory\n","        self.model = None\n","        self.threshold = 0.314\n","        self.preprocessing_handler = PreprocessingHandler(file_directory)  # Initialiser le gestionnaire de prétraitement\n","        self.load_model()\n","\n","    def load_model(self):\n","        \"\"\"Charge le modèle sauvegardé.\"\"\"\n","        print(f\"Chargement du modèle depuis {self.model_path}...\")\n","        try:\n","            self.model = pickle.load(open(self.model_path, 'rb'))\n","            print(\"Modèle chargé avec succès.\")\n","        except FileNotFoundError:\n","            print(f\"Erreur : le fichier du modèle '{self.model_path}' est introuvable.\")\n","            print(\"Veuillez vous assurer que le fichier .pkl du modèle existe et que le chemin est correct.\")\n","            self.model = None  # Le modèle ne peut pas être chargé\n","        except Exception as e:\n","            print(f\"Erreur lors du chargement du modèle : {e}\")\n","            self.model = None\n","\n","    def preprocess_new_data(self, data):\n","        \"\"\"\n","        Prétraite les nouvelles données brutes avant la prédiction.\n","        Cette fonction encapsule toutes les étapes de prétraitement\n","        et d'ingénierie des caractéristiques nécessaires.\n","        \"\"\"\n","        print(\"Prétraitement des nouvelles données pour la prédiction...\")\n","        new_data_processed = self.preprocessing_handler.create_new_features(data.copy())\n","\n","        if self.preprocessing_handler.final_cols is not None:\n","            print(\"Alignement des colonnes des données traitées avec les colonnes finales...\")\n","            final_columns = self.preprocessing_handler.final_cols\n","            missing_cols_in_test = set(final_columns) - set(new_data_processed.columns)\n","            for col in missing_cols_in_test:\n","                new_data_processed[col] = 0  # Ajouter les colonnes manquantes avec des zéros\n","\n","            extra_cols_in_test = set(new_data_processed.columns) - set(final_columns)\n","            new_data_processed = new_data_processed.drop(columns=list(extra_cols_in_test), errors='ignore')\n","\n","            new_data_processed = new_data_processed[final_columns]\n","            print(\"Alignement des colonnes terminé.\")\n","        else:\n","            print(\"Attention : final_cols_for_align non chargé par PreprocessingHandler. Impossible d’aligner correctement les colonnes.\")\n","\n","        gc.collect()\n","        print(\"Nouvelles données prétraitées.\")\n","        return new_data_processed\n","\n","    def predict(self, data_for_prediction):\n","        \"\"\"\n","        Effectue des prédictions sur les données préparées.\n","        \"\"\"\n","        if self.model is None:\n","            print(\"Le modèle n’a pas pu être chargé. Impossible d’effectuer des prédictions.\")\n","            return None, None\n","\n","        print(\"Réalisation des prédictions...\")\n","        try:\n","            if hasattr(self.model, 'predict_proba'):\n","                probabilities = self.model.predict_proba(data_for_prediction)[:, 1]  # Probabilité pour la classe positive\n","            elif hasattr(self.model, 'predict'):\n","                probabilities = self.model.predict(data_for_prediction)\n","            else:\n","                print(\"Le modèle ne possède pas de méthodes predict_proba ou predict.\")\n","                return None, None\n","\n","            if hasattr(self.model, 'predict_proba'):\n","                predictions_class = (probabilities > self.threshold).astype(int)\n","            elif hasattr(self.model, 'predict'):\n","                predictions_class = None  # Pas de prédiction de classe si le modèle ne donne pas de probas\n","                print(\"Le modèle ne fournit pas directement de probabilités de classe. Prédiction de classe ignorée.\")\n","            else:\n","                predictions_class = None\n","\n","            print(\"Prédictions terminées.\")\n","            return probabilities, predictions_class\n","        except Exception as e:\n","            print(f\"Erreur pendant la prédiction : {e}\")\n","            return None, None\n","\n","    def final_function_2(self, test_datapoint, targets_func_2=None):\n","        \"\"\"\n","        Fonction finale pour la pipeline de prédiction. Orchestration du prétraitement, de la prédiction et de l'évaluation.\n","\n","        Entrées :\n","            test_datapoint : pandas.DataFrame, les données brutes sur lesquelles effectuer des prédictions.\n","            targets_func_2 : pandas.Series ou numpy.array, facultatif, les vraies étiquettes pour l’évaluation.\n","\n","        Sorties :\n","            Un dictionnaire contenant les résultats de la prédiction et les métriques d’évaluation si les cibles sont fournies.\n","        \"\"\"\n","        start_time = time.time()\n","        print(\"\\n----------------------------------------------------------------------------------------------------\")\n","        print(\"Démarrage de la pipeline de prédiction...\")\n","\n","        # Étape 1 : Prétraiter les données d'entrée\n","        processed_data = self.preprocess_new_data(test_datapoint)\n","\n","        # Étape 2 : Effectuer les prédictions\n","        # Passer les données transformées à la fonction predict\n","        probabilities, predictions = self.predict(processed_data)\n","\n","        results = {\n","            \"probabilities\": probabilities,\n","            \"predictions_class\": predictions\n","        }\n","\n","        # Étape 3 : Évaluer la performance du modèle si les étiquettes sont connues\n","        if targets_func_2 is not None and probabilities is not None:\n","            print(\"\\nCalcul des métriques de performance...\")\n","            try:\n","                roc_auc = roc_auc_score(targets_func_2, probabilities)\n","                print(f\"Score ROC-AUC = {roc_auc}\")\n","                results[\"roc_auc_score\"] = roc_auc\n","                recall = recall_score(targets_func_2, predictions)\n","                print(f\"Score Recall = {recall}\")\n","                results[\"recall_score\"] = recall\n","            except ValueError as e:\n","                print(f\"Impossible de calculer le score ROC-AUC : {e}. Assurez-vous qu’il y ait au moins deux valeurs cibles différentes.\")\n","                print(f\"Impossible de calculer le score Recall : {e}. Assurez-vous qu’il y ait au moins deux valeurs cibles différentes.\")\n","        else:\n","            print(\"Aucune étiquette fournie ou échec de la prédiction, évaluation ignorée.\")\n","\n","        end_time = time.time()\n","        time_elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(end_time - start_time))\n","        print(f\"Temps total d’exécution de la prédiction = {time_elapsed}\")\n","        print(\"----------------------------------------------------------------------------------------------------\")\n","\n","        return results\n"],"metadata":{"id":"xkcFDMH9plFi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SEaESWVcA5SS"},"source":["## Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:30:02.306395Z","start_time":"2020-10-30T01:29:58.617573Z"},"id":"YyRRdvH8A5SU"},"outputs":[],"source":["train_data = pd.read_csv('/content/drive/MyDrive/Scoring-Projet/data/application_train.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/Scoring-Projet/data/application_test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-10-30T01:30:05.859476Z","start_time":"2020-10-30T01:30:05.818597Z"},"id":"rzntZgzHA5SX","outputId":"8521f834-b189-4c39-d085-dcdf59c35a6b","colab":{"base_uri":"https://localhost:8080/","height":147},"executionInfo":{"status":"ok","timestamp":1751455131955,"user_tz":-120,"elapsed":75,"user":{"displayName":"fernanda","userId":"03477892367761689118"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Out test query point for Testing Function 1 of pipeline is:\n"]},{"output_type":"display_data","data":{"text/plain":["       SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n","11859      186139         Cash loans           F            N               N   \n","\n","       CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n","11859             0          157500.0    450000.0      21649.5   \n","\n","       AMT_GOODS_PRICE  ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n","11859         450000.0  ...                0                0   \n","\n","      FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n","11859                0                0                        0.0   \n","\n","       AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n","11859                        0.0                         0.0   \n","\n","       AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n","11859                        0.0                        1.0   \n","\n","       AMT_REQ_CREDIT_BUREAU_YEAR  \n","11859                         0.0  \n","\n","[1 rows x 121 columns]"],"text/html":["\n","  <div id=\"df-905f458d-29ca-4336-9ecf-dc3995d27544\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SK_ID_CURR</th>\n","      <th>NAME_CONTRACT_TYPE</th>\n","      <th>CODE_GENDER</th>\n","      <th>FLAG_OWN_CAR</th>\n","      <th>FLAG_OWN_REALTY</th>\n","      <th>CNT_CHILDREN</th>\n","      <th>AMT_INCOME_TOTAL</th>\n","      <th>AMT_CREDIT</th>\n","      <th>AMT_ANNUITY</th>\n","      <th>AMT_GOODS_PRICE</th>\n","      <th>...</th>\n","      <th>FLAG_DOCUMENT_18</th>\n","      <th>FLAG_DOCUMENT_19</th>\n","      <th>FLAG_DOCUMENT_20</th>\n","      <th>FLAG_DOCUMENT_21</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11859</th>\n","      <td>186139</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>0</td>\n","      <td>157500.0</td>\n","      <td>450000.0</td>\n","      <td>21649.5</td>\n","      <td>450000.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 121 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-905f458d-29ca-4336-9ecf-dc3995d27544')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-905f458d-29ca-4336-9ecf-dc3995d27544 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-905f458d-29ca-4336-9ecf-dc3995d27544');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_f02b271f-6324-4b21-8d0c-525e3fc67832\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_datapoint_func_1')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f02b271f-6324-4b21-8d0c-525e3fc67832 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('test_datapoint_func_1');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_datapoint_func_1"}},"metadata":{}}],"source":["test_datapoint_func_1 = test_data.sample(1)\n","print(\"Out test query point for Testing Function 1 of pipeline is:\")\n","display(test_datapoint_func_1)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"36450c81","executionInfo":{"status":"ok","timestamp":1751455181482,"user_tz":-120,"elapsed":45190,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"outputId":"dc3c3e30-1b8e-45f3-eb13-479cc126f64d"},"source":["# Supposons que les DataFrames train_data et test_data sont déjà chargés\n","# Supposons que les classes PreprocessingHandler et FinalPipeline sont déjà définies\n","\n","# Spécifiez le répertoire où se trouvent les fichiers nécessaires\n","file_directory = '/content/drive/MyDrive/Scoring-Projet/data/'  # Remplacez par votre chemin réel\n","# Spécifiez le chemin vers le modèle entraîné (utile ici pour le prétraitement,\n","# même si preprocess_new_data fait partie de FinalPipeline, qui charge le modèle automatiquement)\n","# On utilise le même chemin de modèle que dans la cellule f74a56bf pour rester cohérent.\n","model_path = '/content/drive/MyDrive/Scoring-Projet/data/Random_Forest_Model.pkl'\n","\n","\n","# Créez une instance de FinalPipeline (qui inclut PreprocessingHandler)\n","# Cela chargera tous les fichiers requis lors de l'initialisation\n","try:\n","    final_pipeline_instance_for_preprocessing_test = FinalPipeline(model_path=model_path, file_directory=file_directory)\n","    print(\"FinalPipeline instanciée avec succès.\")\n","\n","    # Appliquer le prétraitement et l’ingénierie des caractéristiques aux données de test\n","    test_datapoint_func_1 = test_data.sample(1)\n","    # Appeler preprocess_new_data sur l’instance\n","    test_data_processed = final_pipeline_instance_for_preprocessing_test.preprocess_new_data(test_datapoint_func_1.copy())\n","    print(\"Prétraitement des données de test terminé.\")\n","\n","    # Afficher les premières lignes des données traitées pour vérification\n","    print(\"\\nAperçu des données de test traitées :\")\n","    display(test_data_processed.head())\n","\n","except FileNotFoundError as e:\n","    print(f\"Erreur : Un fichier requis est introuvable. Veuillez vérifier le chemin file_directory et vous assurer que tous les fichiers nécessaires existent : {e}\")\n","except Exception as e:\n","    print(f\"Une erreur est survenue lors du prétraitement : {e}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Chargement des fichiers requis pour le prétraitement...\n","Tous les fichiers requis ont été chargés avec succès.\n","Chargement du modèle depuis /content/drive/MyDrive/Scoring-Projet/data/Random_Forest_Model.pkl...\n","Modèle chargé avec succès.\n","FinalPipeline instanciée avec succès.\n","Prétraitement des nouvelles données pour la prédiction...\n","Creating new features...\n","Création de nouvelles variables.\n","Alignement des colonnes des données traitées avec les colonnes finales...\n","Alignement des colonnes terminé.\n","Nouvelles données prétraitées.\n","Prétraitement des données de test terminé.\n","\n","Aperçu des données de test traitées :\n"]},{"output_type":"display_data","data":{"text/plain":["   AMT_INTEREST_SUM_FIRST_2  STATUS_LAST_YEAR_1_MEAN_OVERALL  \\\n","0              58402.980469                              2.5   \n","\n","   CODE_REJECT_REASON_MEAN_ALL  AMT_PAYMENT_TOTAL_CURRENT_MIN  \\\n","0                          1.0                            NaN   \n","\n","   CREDIT_TYPE_Cash loan (non-earmarked)_MEAN_OVERALL  AMT_CREDIT_SUM_ALL  \\\n","0                                                0.0             137691.0   \n","\n","   ANNUITY_INCOME_RATIO_MAX_AGG_CODE_GENDER_NAME_FAMILY_STATUS_NAME_INCOME_TYPE  \\\n","0                                                  0                              \n","\n","   NONLIVINGAREA_MODE  CREDIT_TYPE_Car loan_MEAN_OVERALL  \\\n","0                 NaN                                0.0   \n","\n","   INTEREST_SHARE_MEAN_FIRST_2  ...  NAME_TYPE_SUITE_MEAN_LAST_5  \\\n","0                     0.424072  ...                          2.0   \n","\n","   AMT_DOWN_PAYMENT_MEAN_ALL  CNT_INSTALMENT_FUTURE_MEAN_ACTIVE_SUM  \\\n","0                        NaN                                    7.5   \n","\n","   AMT_DECLINED_SUM_ALL  CNT_INSTALMENT_FUTURE_MEAN_YEAR_1_SUM  \\\n","0              -25191.0                               6.816406   \n","\n","   CNT_PROLONGED_MAX_OVERDUE_MUL_MEAN_OVERALL  \\\n","0                                         NaN   \n","\n","   MAX_AMT_OVERDUE_DURATION_RATIO_MEAN_OVERALL  \\\n","0                                          NaN   \n","\n","   AMT_INCOME_TOTAL_MIN_AGG_FLAG_OWN_CAR_FLAG_OWN_REALTY_NAME_INCOME_TYPE  \\\n","0                                                  0                        \n","\n","   EXT_SOURCE_1_MEAN_AGG_NAME_EDUCATION_TYPE_NAME_INCOME_TYPE_OCCUPATION_TYPE  \\\n","0                                                  0                            \n","\n","   AMT_CREDIT_GOODS_RATIO_MIN_LAST_5  \n","0                            1.22392  \n","\n","[1 rows x 1225 columns]"],"text/html":["\n","  <div id=\"df-74990c76-fa6f-4135-ba6b-3e4bc824710a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AMT_INTEREST_SUM_FIRST_2</th>\n","      <th>STATUS_LAST_YEAR_1_MEAN_OVERALL</th>\n","      <th>CODE_REJECT_REASON_MEAN_ALL</th>\n","      <th>AMT_PAYMENT_TOTAL_CURRENT_MIN</th>\n","      <th>CREDIT_TYPE_Cash loan (non-earmarked)_MEAN_OVERALL</th>\n","      <th>AMT_CREDIT_SUM_ALL</th>\n","      <th>ANNUITY_INCOME_RATIO_MAX_AGG_CODE_GENDER_NAME_FAMILY_STATUS_NAME_INCOME_TYPE</th>\n","      <th>NONLIVINGAREA_MODE</th>\n","      <th>CREDIT_TYPE_Car loan_MEAN_OVERALL</th>\n","      <th>INTEREST_SHARE_MEAN_FIRST_2</th>\n","      <th>...</th>\n","      <th>NAME_TYPE_SUITE_MEAN_LAST_5</th>\n","      <th>AMT_DOWN_PAYMENT_MEAN_ALL</th>\n","      <th>CNT_INSTALMENT_FUTURE_MEAN_ACTIVE_SUM</th>\n","      <th>AMT_DECLINED_SUM_ALL</th>\n","      <th>CNT_INSTALMENT_FUTURE_MEAN_YEAR_1_SUM</th>\n","      <th>CNT_PROLONGED_MAX_OVERDUE_MUL_MEAN_OVERALL</th>\n","      <th>MAX_AMT_OVERDUE_DURATION_RATIO_MEAN_OVERALL</th>\n","      <th>AMT_INCOME_TOTAL_MIN_AGG_FLAG_OWN_CAR_FLAG_OWN_REALTY_NAME_INCOME_TYPE</th>\n","      <th>EXT_SOURCE_1_MEAN_AGG_NAME_EDUCATION_TYPE_NAME_INCOME_TYPE_OCCUPATION_TYPE</th>\n","      <th>AMT_CREDIT_GOODS_RATIO_MIN_LAST_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58402.980469</td>\n","      <td>2.5</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>137691.0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>0.424072</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>7.5</td>\n","      <td>-25191.0</td>\n","      <td>6.816406</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1.22392</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows × 1225 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74990c76-fa6f-4135-ba6b-3e4bc824710a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-74990c76-fa6f-4135-ba6b-3e4bc824710a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-74990c76-fa6f-4135-ba6b-3e4bc824710a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f74a56bf","executionInfo":{"status":"ok","timestamp":1751455190919,"user_tz":-120,"elapsed":5999,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"outputId":"ef4bf825-873a-4485-972f-1b88bc8ff622"},"source":["# Assuming test_data DataFrame is already loaded\n","# Assuming the FinalPipeline class definition (from cell xkcFDMH9plFi) is already executed\n","\n","# Spécifiez le chemin vers le modèle XGBoost entraîné\n","model_path = '/content/drive/MyDrive/Scoring-Projet/data/Random_Forest_Model.pkl' # Supposé être le modèle à utiliser\n","# Spécifiez le répertoire contenant les autres fichiers nécessaires (comme les fichiers .pkl pour le prétraitement)\n","file_directory = '/content/drive/MyDrive/Scoring-Projet/data/'\n","\n","# Créez une instance de la classe FinalPipeline\n","try:\n","    final_pipeline_instance = FinalPipeline(model_path=model_path, file_directory=file_directory)\n","    print(\"FinalPipeline instanciée avec succès.\")\n","\n","    # Appliquez la méthode final_function_2 aux données de test brutes\n","    # La fonction gère le prétraitement en interne\n","    print(\"\\nApplication de final_function_2 aux données de test...\")\n","    prediction_results = final_pipeline_instance.final_function_2(test_datapoint_func_1) # Données de test brutes\n","\n","    # Affichez les prédictions (probabilités et étiquettes de classe)\n","    print(\"\\nRésultats de la prédiction :\")\n","    print(\"Probabilités :\", prediction_results.get(\"probabilities\"))\n","    print(\"Étiquettes de classe prédites :\", prediction_results.get(\"predictions_class\"))\n","\n","except FileNotFoundError as e:\n","    print(f\"Erreur : Un fichier requis est introuvable. Veuillez vérifier les chemins du modèle et du répertoire de données : {e}\")\n","except Exception as e:\n","    print(f\"Une erreur est survenue pendant l'exécution du pipeline de prédiction : {e}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Chargement des fichiers requis pour le prétraitement...\n","Tous les fichiers requis ont été chargés avec succès.\n","Chargement du modèle depuis /content/drive/MyDrive/Scoring-Projet/data/Random_Forest_Model.pkl...\n","Modèle chargé avec succès.\n","FinalPipeline instanciée avec succès.\n","\n","Application de final_function_2 aux données de test...\n","\n","----------------------------------------------------------------------------------------------------\n","Démarrage de la pipeline de prédiction...\n","Prétraitement des nouvelles données pour la prédiction...\n","Creating new features...\n","Création de nouvelles variables.\n","Alignement des colonnes des données traitées avec les colonnes finales...\n","Alignement des colonnes terminé.\n","Nouvelles données prétraitées.\n","Réalisation des prédictions...\n","Prédictions terminées.\n","Aucune étiquette fournie ou échec de la prédiction, évaluation ignorée.\n","Temps total d’exécution de la prédiction = 00:00:03\n","----------------------------------------------------------------------------------------------------\n","\n","Résultats de la prédiction :\n","Probabilités : [0.30122746]\n","Étiquettes de classe prédites : [0]\n"]}]},{"cell_type":"code","source":["# Sélectionner aléatoirement 50 lignes depuis les données d'entraînement comme jeu de test\n","test_datapoint_func_2 = train_data.sample(50).copy()\n","\n","# Extraire la colonne cible 'TARGET' pour l'évaluation\n","targets_func_2 = test_datapoint_func_2.pop('TARGET')\n","\n","# Afficher quelques exemples du jeu de test sélectionné\n","print(\"Quelques exemples de points de test pour tester la fonction 2 du pipeline :\")\n","display(test_datapoint_func_2.head(5))\n","\n","# Afficher les étiquettes cibles (valeurs réelles) correspondantes à ces points de test\n","print(\"Étiquettes cibles de ces points de données :\")\n","print(targets_func_2.values[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":308},"id":"-CpmOUMwg8KM","executionInfo":{"status":"ok","timestamp":1751455223944,"user_tz":-120,"elapsed":82,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"outputId":"279ba87e-dd23-41b7-ef09-a1c159bcabd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Quelques exemples de points de test pour tester la fonction 2 du pipeline :\n"]},{"output_type":"display_data","data":{"text/plain":["        SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n","241332      379433    Revolving loans           F            N   \n","74762       186701         Cash loans           F            N   \n","92762       207704         Cash loans           F            N   \n","73570       185315         Cash loans           F            N   \n","60303       169919         Cash loans           M            Y   \n","\n","       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n","241332               Y             1           90000.0    202500.0   \n","74762                Y             1          337500.0   1358883.0   \n","92762                N             0          135000.0    352044.0   \n","73570                Y             0           89100.0    314100.0   \n","60303                Y             0          202500.0    127350.0   \n","\n","        AMT_ANNUITY  AMT_GOODS_PRICE  ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n","241332      10125.0         202500.0  ...                0                0   \n","74762       48937.5        1098000.0  ...                0                0   \n","92762       12645.0         247500.0  ...                0                0   \n","73570       13833.0         225000.0  ...                0                0   \n","60303        8640.0         112500.0  ...                0                0   \n","\n","       FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n","241332                0                0                        NaN   \n","74762                 0                0                        0.0   \n","92762                 0                0                        0.0   \n","73570                 0                0                        0.0   \n","60303                 0                0                        0.0   \n","\n","        AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n","241332                        NaN                         NaN   \n","74762                         0.0                         0.0   \n","92762                         0.0                         0.0   \n","73570                         0.0                         0.0   \n","60303                         0.0                         0.0   \n","\n","        AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n","241332                        NaN                        NaN   \n","74762                         0.0                        0.0   \n","92762                         0.0                        0.0   \n","73570                         0.0                        0.0   \n","60303                         0.0                        0.0   \n","\n","        AMT_REQ_CREDIT_BUREAU_YEAR  \n","241332                         NaN  \n","74762                          2.0  \n","92762                          2.0  \n","73570                          4.0  \n","60303                          0.0  \n","\n","[5 rows x 121 columns]"],"text/html":["\n","  <div id=\"df-11cc8534-94a6-45a5-a1fe-1cd71245cc8c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SK_ID_CURR</th>\n","      <th>NAME_CONTRACT_TYPE</th>\n","      <th>CODE_GENDER</th>\n","      <th>FLAG_OWN_CAR</th>\n","      <th>FLAG_OWN_REALTY</th>\n","      <th>CNT_CHILDREN</th>\n","      <th>AMT_INCOME_TOTAL</th>\n","      <th>AMT_CREDIT</th>\n","      <th>AMT_ANNUITY</th>\n","      <th>AMT_GOODS_PRICE</th>\n","      <th>...</th>\n","      <th>FLAG_DOCUMENT_18</th>\n","      <th>FLAG_DOCUMENT_19</th>\n","      <th>FLAG_DOCUMENT_20</th>\n","      <th>FLAG_DOCUMENT_21</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n","      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>241332</th>\n","      <td>379433</td>\n","      <td>Revolving loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>1</td>\n","      <td>90000.0</td>\n","      <td>202500.0</td>\n","      <td>10125.0</td>\n","      <td>202500.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>74762</th>\n","      <td>186701</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>1</td>\n","      <td>337500.0</td>\n","      <td>1358883.0</td>\n","      <td>48937.5</td>\n","      <td>1098000.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>92762</th>\n","      <td>207704</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>N</td>\n","      <td>0</td>\n","      <td>135000.0</td>\n","      <td>352044.0</td>\n","      <td>12645.0</td>\n","      <td>247500.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>73570</th>\n","      <td>185315</td>\n","      <td>Cash loans</td>\n","      <td>F</td>\n","      <td>N</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>89100.0</td>\n","      <td>314100.0</td>\n","      <td>13833.0</td>\n","      <td>225000.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>60303</th>\n","      <td>169919</td>\n","      <td>Cash loans</td>\n","      <td>M</td>\n","      <td>Y</td>\n","      <td>Y</td>\n","      <td>0</td>\n","      <td>202500.0</td>\n","      <td>127350.0</td>\n","      <td>8640.0</td>\n","      <td>112500.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 121 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11cc8534-94a6-45a5-a1fe-1cd71245cc8c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-11cc8534-94a6-45a5-a1fe-1cd71245cc8c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-11cc8534-94a6-45a5-a1fe-1cd71245cc8c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-a32f34c7-89b5-4b19-b88a-9131d90d5fa7\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a32f34c7-89b5-4b19-b88a-9131d90d5fa7')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-a32f34c7-89b5-4b19-b88a-9131d90d5fa7 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Étiquettes cibles de ces points de données :\n","[0 0 0 0 0]\n"]}]},{"cell_type":"code","source":["# Supposons que le DataFrame test_data est déjà chargé\n","# Supposons que la classe FinalPipeline (de la cellule xkcFDMH9plFi) est déjà définie\n","\n","# Spécifiez le chemin vers le modèle XGBoost entraîné (ici un modèle Random Forest est utilisé)\n","model_path = '/content/drive/MyDrive/Scoring-Projet/data/Random_Forest_Model.pkl'  # On suppose que c’est le modèle à utiliser\n","# Spécifiez le répertoire contenant les autres fichiers nécessaires (comme les fichiers .pkl pour le prétraitement)\n","file_directory = '/content/drive/MyDrive/Scoring-Projet/data/'\n","\n","# Créez une instance de la classe FinalPipeline\n","try:\n","    final_pipeline_instance = FinalPipeline(model_path=model_path, file_directory=file_directory)\n","    print(\"FinalPipeline instanciée avec succès.\")\n","\n","    # Appliquez la fonction final_function_2 aux données brutes de test\n","    # La fonction s’occupera du prétraitement en interne\n","    print(\"\\nApplication de final_function_2 aux données de test...\")\n","    prediction_results = final_pipeline_instance.final_function_2(test_datapoint_func_2, targets_func_2=targets_func_2)  # On passe les données brutes\n","\n","    # Affiche les prédictions (probabilités et classes prédites)\n","    print(\"\\nRésultats de la prédiction :\")\n","    print(\"Probabilités :\", prediction_results.get(\"probabilities\"))\n","    print(\"Classes prédites :\", prediction_results.get(\"predictions_class\"))\n","\n","except FileNotFoundError as e:\n","    print(f\"Erreur : Un fichier requis est introuvable. Veuillez vérifier les chemins vers le modèle et le répertoire de données : {e}\")\n","except Exception as e:\n","    print(f\"Une erreur est survenue pendant le pipeline de prédiction : {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeuxnsTthDeY","executionInfo":{"status":"ok","timestamp":1751455233649,"user_tz":-120,"elapsed":6632,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"outputId":"a7325d73-c106-493f-f456-12fcf1081351"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Chargement des fichiers requis pour le prétraitement...\n","Tous les fichiers requis ont été chargés avec succès.\n","Chargement du modèle depuis /content/drive/MyDrive/Scoring-Projet/data/Random_Forest_Model.pkl...\n","Modèle chargé avec succès.\n","FinalPipeline instanciée avec succès.\n","\n","Application de final_function_2 aux données de test...\n","\n","----------------------------------------------------------------------------------------------------\n","Démarrage de la pipeline de prédiction...\n","Prétraitement des nouvelles données pour la prédiction...\n","Creating new features...\n","Création de nouvelles variables.\n","Alignement des colonnes des données traitées avec les colonnes finales...\n","Alignement des colonnes terminé.\n","Nouvelles données prétraitées.\n","Réalisation des prédictions...\n","Prédictions terminées.\n","\n","Calcul des métriques de performance...\n","Score ROC-AUC = 0.5422222222222223\n","Score Recall = 0.4\n","Temps total d’exécution de la prédiction = 00:00:02\n","----------------------------------------------------------------------------------------------------\n","\n","Résultats de la prédiction :\n","Probabilités : [0.29767722 0.32079459 0.30834351 0.31705161 0.32765391 0.31917446\n"," 0.3016147  0.30108723 0.30722782 0.32886699 0.30966108 0.31735766\n"," 0.22724526 0.30155347 0.32379347 0.32442978 0.29729166 0.32198694\n"," 0.32382839 0.31014248 0.30623753 0.31949721 0.31263154 0.30520777\n"," 0.30194885 0.30739115 0.32451304 0.30348756 0.32974363 0.30225777\n"," 0.31544073 0.29293471 0.31644658 0.32481773 0.30892949 0.31431281\n"," 0.31097306 0.30888006 0.30770004 0.21405012 0.31990507 0.31214976\n"," 0.32591126 0.23576759 0.3304741  0.31851479 0.31135778 0.31766923\n"," 0.30864274 0.31033838]\n","Classes prédites : [0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0\n"," 0 0 0 1 0 1 0 1 1 0 1 0 0]\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"datasansmythe@gmail.com\""],"metadata":{"id":"tZ6OKhuEB_7v","executionInfo":{"status":"ok","timestamp":1751458019566,"user_tz":-120,"elapsed":132,"user":{"displayName":"fernanda","userId":"03477892367761689118"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!git config --global user.name \"Datasansmythe\""],"metadata":{"id":"smiXIXRtCIm0","executionInfo":{"status":"ok","timestamp":1751458046342,"user_tz":-120,"elapsed":92,"user":{"displayName":"fernanda","userId":"03477892367761689118"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/datasansmythe/home-crdit.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-8f6j8nCIp_","executionInfo":{"status":"ok","timestamp":1751458147052,"user_tz":-120,"elapsed":825,"user":{"displayName":"fernanda","userId":"03477892367761689118"}},"outputId":"6afa08de-56f1-4e1c-961a-78a9d0900ca4"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'home-crdit'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 6 (delta 0), reused 6 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (6/6), 24.53 KiB | 4.09 MiB/s, done.\n"]}]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/Scoring-Projet /content/ton-depot/"],"metadata":{"id":"JaQHjpkJCIta"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Ec1AnlJoCIv-"},"execution_count":null,"outputs":[]}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[],"gpuType":"V28"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}